// Advanced Caption Service - YouTube-style captions with subtitle files and auto-generation
import * as DocumentPicker from 'expo-document-picker';
import * as FileSystem from 'expo-file-system';
import { getDownloadURL, ref, uploadBytes } from 'firebase/storage';
import { storage } from '../firebaseConfig';

export interface CaptionSegment {
  id: string;
  startTime: number; // in seconds
  endTime: number; // in seconds
  text: string;
  speaker?: string; // optional speaker identification
}

export interface CaptionTrack {
  id: string;
  language: string;
  label: string; // e.g., "English", "English (Auto-generated)"
  kind: 'subtitles' | 'captions' | 'descriptions';
  isDefault: boolean;
  isAutoGenerated: boolean;
  segments: CaptionSegment[];
  vttUrl?: string; // URL to the WebVTT file
  srtUrl?: string; // URL to the SRT file
}

export interface VideoWithCaptions {
  assetId: string;
  playbackUrl: string;
  thumbnailUrl: string;
  username: string;
  userId: string;
  views?: number;
  createdAt: string;
  caption?: string; // Short description caption
  captionTracks?: CaptionTrack[]; // Full subtitle tracks
}

class CaptionService {
  
  // Parse SRT (SubRip) file format
  parseSRT(srtContent: string): CaptionSegment[] {
    const segments: CaptionSegment[] = [];
    const blocks = srtContent.trim().split(/\n\s*\n/);
    
    blocks.forEach((block, index) => {
      const lines = block.trim().split('\n');
      if (lines.length >= 3) {
        const id = lines[0];
        const timeLine = lines[1];
        const text = lines.slice(2).join(' ');
        
        // Parse time format: 00:01:30,500 --> 00:01:33,400
        const timeMatch = timeLine.match(/(\d{2}):(\d{2}):(\d{2}),(\d{3})\s*-->\s*(\d{2}):(\d{2}):(\d{2}),(\d{3})/);
        
        if (timeMatch) {
          const startTime = this.parseTime(timeMatch[1], timeMatch[2], timeMatch[3], timeMatch[4]);
          const endTime = this.parseTime(timeMatch[5], timeMatch[6], timeMatch[7], timeMatch[8]);
          
          segments.push({
            id: `segment_${index}`,
            startTime,
            endTime,
            text: text.replace(/<[^>]*>/g, ''), // Remove HTML tags
          });
        }
      }
    });
    
    return segments;
  }
  
  // Parse WebVTT file format
  parseVTT(vttContent: string): CaptionSegment[] {
    const segments: CaptionSegment[] = [];
    const lines = vttContent.split('\n');
    
    let currentSegment: Partial<CaptionSegment> | null = null;
    let segmentIndex = 0;
    
    for (let i = 0; i < lines.length; i++) {
      const line = lines[i].trim();
      
      // Skip WEBVTT header and empty lines
      if (line === 'WEBVTT' || line === '') continue;
      
      // Time line format: 00:01:30.500 --> 00:01:33.400
      const timeMatch = line.match(/(\d{2}):(\d{2}):(\d{2})\.(\d{3})\s*-->\s*(\d{2}):(\d{2}):(\d{2})\.(\d{3})/);
      
      if (timeMatch) {
        // Save previous segment if exists
        if (currentSegment && currentSegment.text) {
          segments.push(currentSegment as CaptionSegment);
        }
        
        // Start new segment
        const startTime = this.parseTime(timeMatch[1], timeMatch[2], timeMatch[3], timeMatch[4]);
        const endTime = this.parseTime(timeMatch[5], timeMatch[6], timeMatch[7], timeMatch[8]);
        
        currentSegment = {
          id: `segment_${segmentIndex++}`,
          startTime,
          endTime,
          text: '',
        };
      } else if (currentSegment && line) {
        // Add text to current segment
        currentSegment.text = currentSegment.text ? `${currentSegment.text} ${line}` : line;
      }
    }
    
    // Add last segment
    if (currentSegment && currentSegment.text) {
      segments.push(currentSegment as CaptionSegment);
    }
    
    return segments;
  }
  
  // Helper function to parse time components to seconds
  private parseTime(hours: string, minutes: string, seconds: string, milliseconds: string): number {
    return parseInt(hours) * 3600 + parseInt(minutes) * 60 + parseInt(seconds) + parseInt(milliseconds) / 1000;
  }
  
  // Generate WebVTT content from segments
  generateVTT(segments: CaptionSegment[]): string {
    let vtt = 'WEBVTT\n\n';
    
    segments.forEach((segment) => {
      const startTime = this.formatTimeVTT(segment.startTime);
      const endTime = this.formatTimeVTT(segment.endTime);
      
      vtt += `${startTime} --> ${endTime}\n`;
      vtt += `${segment.text}\n\n`;
    });
    
    return vtt;
  }
  
  // Generate SRT content from segments
  generateSRT(segments: CaptionSegment[]): string {
    let srt = '';
    
    segments.forEach((segment, index) => {
      const startTime = this.formatTimeSRT(segment.startTime);
      const endTime = this.formatTimeSRT(segment.endTime);
      
      srt += `${index + 1}\n`;
      srt += `${startTime} --> ${endTime}\n`;
      srt += `${segment.text}\n\n`;
    });
    
    return srt;
  }
  
  // Format time for VTT (HH:MM:SS.mmm)
  private formatTimeVTT(seconds: number): string {
    const hours = Math.floor(seconds / 3600);
    const minutes = Math.floor((seconds % 3600) / 60);
    const secs = Math.floor(seconds % 60);
    const milliseconds = Math.floor((seconds % 1) * 1000);
    
    return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${milliseconds.toString().padStart(3, '0')}`;
  }
  
  // Format time for SRT (HH:MM:SS,mmm)
  private formatTimeSRT(seconds: number): string {
    const hours = Math.floor(seconds / 3600);
    const minutes = Math.floor((seconds % 3600) / 60);
    const secs = Math.floor(seconds % 60);
    const milliseconds = Math.floor((seconds % 1) * 1000);
    
    return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')},${milliseconds.toString().padStart(3, '0')}`;
  }
  
  // Pick and upload caption file
  async uploadCaptionFile(videoAssetId: string): Promise<CaptionTrack | null> {
    try {
      console.log('üìÅ Opening caption file picker...');
      
      const result = await DocumentPicker.getDocumentAsync({
        type: ['text/vtt', 'text/srt', 'text/plain', '*/*'],
        copyToCacheDirectory: true,
      });
      
      if (result.canceled) {
        console.log('üìÅ Caption file picker cancelled');
        return null;
      }
      
      const file = result.assets[0];
      console.log('üìÅ Caption file selected:', file.name, file.mimeType);
      
      // Read file content
      const fileContent = await FileSystem.readAsStringAsync(file.uri);
      console.log('üìÑ Caption file content length:', fileContent.length);
      
      // Determine file type and parse
      let segments: CaptionSegment[] = [];
      let fileType: 'srt' | 'vtt' = 'srt';
      
      if (file.name?.toLowerCase().endsWith('.vtt') || fileContent.startsWith('WEBVTT')) {
        segments = this.parseVTT(fileContent);
        fileType = 'vtt';
        console.log('üé¨ Parsed WebVTT file with', segments.length, 'segments');
      } else {
        segments = this.parseSRT(fileContent);
        fileType = 'srt';
        console.log('üé¨ Parsed SRT file with', segments.length, 'segments');
      }
      
      if (segments.length === 0) {
        throw new Error('No valid caption segments found in file');
      }
      
      // Upload both VTT and SRT versions to Firebase Storage
      const vttContent = this.generateVTT(segments);
      const srtContent = this.generateSRT(segments);
      
      const vttRef = ref(storage, `captions/${videoAssetId}.vtt`);
      const srtRef = ref(storage, `captions/${videoAssetId}.srt`);
      
      const [vttUrl, srtUrl] = await Promise.all([
        uploadBytes(vttRef, new Blob([vttContent], { type: 'text/vtt' })).then(() => getDownloadURL(vttRef)),
        uploadBytes(srtRef, new Blob([srtContent], { type: 'text/srt' })).then(() => getDownloadURL(srtRef))
      ]);
      
      console.log('‚òÅÔ∏è Caption files uploaded to Firebase Storage');
      
      // Create caption track
      const captionTrack: CaptionTrack = {
        id: `${videoAssetId}_manual`,
        language: 'en', // Default to English, could be detected or specified
        label: 'English',
        kind: 'subtitles',
        isDefault: true,
        isAutoGenerated: false,
        segments,
        vttUrl,
        srtUrl,
      };
      
      return captionTrack;
      
    } catch (error) {
      console.error('‚ùå Failed to upload caption file:', error);
      throw error;
    }
  }
  
  // Generate automatic captions using speech recognition (mock implementation)
  async generateAutoCaptions(videoAssetId: string, audioUrl?: string): Promise<CaptionTrack | null> {
    try {
      console.log('ü§ñ Generating automatic captions for video:', videoAssetId);
      
      // This is a mock implementation
      // In a real app, you would:
      // 1. Extract audio from video
      // 2. Send audio to speech recognition service (Google Speech-to-Text, AWS Transcribe, etc.)
      // 3. Process the response into timed segments
      
      // Mock auto-generated captions for demonstration
      const mockSegments: CaptionSegment[] = [
        {
          id: 'auto_1',
          startTime: 0,
          endTime: 3,
          text: 'Welcome to my video! This is automatically generated content.',
        },
        {
          id: 'auto_2',
          startTime: 3,
          endTime: 7,
          text: 'Auto captions help make videos accessible to everyone.',
        },
        {
          id: 'auto_3',
          startTime: 7,
          endTime: 12,
          text: 'You can edit these captions to improve accuracy and timing.',
        },
      ];
      
      // Generate and upload caption files
      const vttContent = this.generateVTT(mockSegments);
      const srtContent = this.generateSRT(mockSegments);
      
      const vttRef = ref(storage, `captions/${videoAssetId}_auto.vtt`);
      const srtRef = ref(storage, `captions/${videoAssetId}_auto.srt`);
      
      const [vttUrl, srtUrl] = await Promise.all([
        uploadBytes(vttRef, new Blob([vttContent], { type: 'text/vtt' })).then(() => getDownloadURL(vttRef)),
        uploadBytes(srtRef, new Blob([srtContent], { type: 'text/srt' })).then(() => getDownloadURL(srtRef))
      ]);
      
      console.log('ü§ñ Auto captions generated and uploaded');
      
      const captionTrack: CaptionTrack = {
        id: `${videoAssetId}_auto`,
        language: 'en',
        label: 'English (Auto-generated)',
        kind: 'captions',
        isDefault: false,
        isAutoGenerated: true,
        segments: mockSegments,
        vttUrl,
        srtUrl,
      };
      
      return captionTrack;
      
    } catch (error) {
      console.error('‚ùå Failed to generate auto captions:', error);
      return null;
    }
  }
  
  // Get caption text for a specific time
  getCaptionAtTime(segments: CaptionSegment[], currentTime: number): string | null {
    const activeSegment = segments.find(
      segment => currentTime >= segment.startTime && currentTime <= segment.endTime
    );
    
    return activeSegment?.text || null;
  }
  
  // Get all active captions for a time range (for smooth scrolling)
  getCaptionsInRange(segments: CaptionSegment[], startTime: number, endTime: number): CaptionSegment[] {
    return segments.filter(
      segment => segment.startTime <= endTime && segment.endTime >= startTime
    );
  }
}

export default new CaptionService();
